{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT IR-WA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mara Mart√≠nez: 219330 \n",
    "\n",
    "Pau Puertas: 218872\n",
    "\n",
    "Rosa Al√≥s: 205930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets in the corpus: 2399\n"
     ]
    }
   ],
   "source": [
    "docs_path = 'dataset_tweets_WHO.txt'\n",
    "dictionary = []\n",
    "with open(docs_path) as fp:\n",
    "    tweets = json.loads(fp.read())\n",
    "    \n",
    "print(\"Total number of tweets in the corpus: {}\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the article text (title + body) removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "    line = line.lower() ## Transform in lowercase\n",
    "    line = line.split() ## Tokenize the text to get a list of terms\n",
    "    line =  [l for l in line if l not in stop_words] ##eliminate the stopwords (HINT: use List Comprehension)\n",
    "    line = [stemmer.stem(l) for l in line] ## perform stemming (HINT: use List Comprehension)\n",
    "    line = [l for l in line if \"https://\" not in l ] ##deletes the items that are url links \n",
    "    \n",
    "    line = [remove_emojis(l) for l in line ] ##deletes the items that are emojis\n",
    "    line = [l for l in line if \"\" != l ]\n",
    "    #print(line)\n",
    "    ## END CODE\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis (l):\n",
    "    \"\"\"If the string \"l\" is an emoji it deletes it. \n",
    "    \n",
    "    Arguments:\n",
    "    l-- string word to be processed\n",
    "    \n",
    "    Returns: \n",
    "    word-- string equal to \"l\" if it's not an emoji and \"\" otherwise. \n",
    "    \"\"\"\n",
    "    emoji_pattern = re.compile(\"[\"  \n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "       \n",
    "    word = emoji_pattern.sub(r'', l)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing (info): \n",
    "    \"\"\"Processes each tweet given a list of tweets.\n",
    "    \n",
    "    Argument: \n",
    "    info-- list of string containing each tweet\n",
    "    \n",
    "    Return:\n",
    "    clean_tweets -- list of lists of strings containing each tweet cleaned and separated by words. \n",
    "    \"\"\"\n",
    "    clean_tweets = []\n",
    "    for tweet in info: \n",
    "        clean_tweets.append(build_terms(tweet))\n",
    "        \n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>contributors</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Oct 13 09:15:58 +0000 2021</td>\n",
       "      <td>1448215930178310144</td>\n",
       "      <td>1448215930178310144</td>\n",
       "      <td>It's International Day for Disaster Risk Reduc...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 274]</td>\n",
       "      <td>{'hashtags': [{'text': 'OpenWHO', 'indices': [...</td>\n",
       "      <td>{'media': [{'id': 1448215398814560259, 'id_str...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>1.448208e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Oct 13 08:46:17 +0000 2021</td>\n",
       "      <td>1448208458604584960</td>\n",
       "      <td>1448208458604584960</td>\n",
       "      <td>#COVID19 has shown how health emergencies and ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 241]</td>\n",
       "      <td>{'hashtags': [{'text': 'COVID19', 'indices': [...</td>\n",
       "      <td>{'media': [{'id': 1448208218463875077, 'id_str...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>1.448195e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>119</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tue Oct 12 21:01:38 +0000 2021</td>\n",
       "      <td>1448031127999074306</td>\n",
       "      <td>1448031127999074306</td>\n",
       "      <td>RT @DrTedros: In 1951 Henrietta Lacks died fro...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 139]</td>\n",
       "      <td>{'hashtags': [{'text': 'cervicalcancer', 'indi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Sun Oct 10 06:58:15 +0000 2021</td>\n",
       "      <td>1447094107155931137</td>\n",
       "      <td>1447094107155931137</td>\n",
       "      <td>If someone you know has #depression, here is h...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 213]</td>\n",
       "      <td>{'hashtags': [{'text': 'depression', 'indices'...</td>\n",
       "      <td>{'media': [{'id': 1447093861852106752, 'id_str...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>1.447092e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>152</td>\n",
       "      <td>333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Wed Sep 01 14:24:53 +0000 2021</td>\n",
       "      <td>1433073378844422147</td>\n",
       "      <td>1433073378844422147</td>\n",
       "      <td>\"At the same time, new technologies are giving...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 258]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>1.433073e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          created_at                   id  \\\n",
       "0     Wed Oct 13 09:15:58 +0000 2021  1448215930178310144   \n",
       "1     Wed Oct 13 08:46:17 +0000 2021  1448208458604584960   \n",
       "10    Tue Oct 12 21:01:38 +0000 2021  1448031127999074306   \n",
       "100   Sun Oct 10 06:58:15 +0000 2021  1447094107155931137   \n",
       "1000  Wed Sep 01 14:24:53 +0000 2021  1433073378844422147   \n",
       "\n",
       "                   id_str                                          full_text  \\\n",
       "0     1448215930178310144  It's International Day for Disaster Risk Reduc...   \n",
       "1     1448208458604584960  #COVID19 has shown how health emergencies and ...   \n",
       "10    1448031127999074306  RT @DrTedros: In 1951 Henrietta Lacks died fro...   \n",
       "100   1447094107155931137  If someone you know has #depression, here is h...   \n",
       "1000  1433073378844422147  \"At the same time, new technologies are giving...   \n",
       "\n",
       "      truncated display_text_range  \\\n",
       "0         False           [0, 274]   \n",
       "1         False           [0, 241]   \n",
       "10        False           [0, 139]   \n",
       "100       False           [0, 213]   \n",
       "1000      False           [0, 258]   \n",
       "\n",
       "                                               entities  \\\n",
       "0     {'hashtags': [{'text': 'OpenWHO', 'indices': [...   \n",
       "1     {'hashtags': [{'text': 'COVID19', 'indices': [...   \n",
       "10    {'hashtags': [{'text': 'cervicalcancer', 'indi...   \n",
       "100   {'hashtags': [{'text': 'depression', 'indices'...   \n",
       "1000  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                      extended_entities  \\\n",
       "0     {'media': [{'id': 1448215398814560259, 'id_str...   \n",
       "1     {'media': [{'id': 1448208218463875077, 'id_str...   \n",
       "10                                                  NaN   \n",
       "100   {'media': [{'id': 1447093861852106752, 'id_str...   \n",
       "1000                                                NaN   \n",
       "\n",
       "                                                 source  \\\n",
       "0     <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "1     <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "10    <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "100   <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "1000  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "\n",
       "      in_reply_to_status_id  ...  coordinates  place contributors  \\\n",
       "0              1.448208e+18  ...         None   None         None   \n",
       "1              1.448195e+18  ...         None   None         None   \n",
       "10                      NaN  ...         None   None         None   \n",
       "100            1.447092e+18  ...         None   None         None   \n",
       "1000           1.433073e+18  ...         None   None         None   \n",
       "\n",
       "     is_quote_status retweet_count favorite_count favorited retweeted  \\\n",
       "0              False            16             52     False     False   \n",
       "1              False            33            119     False     False   \n",
       "10              True            73              0     False     False   \n",
       "100            False           152            333     False     False   \n",
       "1000           False            15             53     False     False   \n",
       "\n",
       "     possibly_sensitive  lang  \n",
       "0                 False    en  \n",
       "1                 False    en  \n",
       "10                  NaN    en  \n",
       "100               False    en  \n",
       "1000                NaN    en  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame.from_dict(tweets, orient='index',\n",
    "                       columns= tweets[\"1\"].keys())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOriginal tweet: \n",
      "\u001b[0m It's International Day for Disaster Risk Reduction\n",
      "\n",
      "#OpenWHO has launched a multi-tiered core curriculum to help equip you with the competencies needed to work within public health emergency response.\n",
      "\n",
      "Start learning today &amp; be #Ready4Response:\n",
      "üëâ https://t.co/hBFFOF0xKL https://t.co/fgZY22RWuS\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1mCleaned and tokenized tweet: \n",
      "\u001b[0m ['intern', 'day', 'disast', 'risk', 'reduct', '#openwho', 'launch', 'multi-ti', 'core', 'curriculum', 'help', 'equip', 'compet', 'need', 'work', 'within', 'public', 'health', 'emerg', 'response.', 'start', 'learn', 'today', '&amp;', '#ready4response:']\n"
     ]
    }
   ],
   "source": [
    "list_tweets = data[\"full_text\"].tolist()\n",
    "clean_tweets = text_processing(list_tweets)\n",
    "print (\"\\033[1m\" + \"Original tweet: \\n\" + \"\\033[0m\", list_tweets[0])\n",
    "print(\"------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "print(\"\\033[1m\" + \"Cleaned and tokenized tweet: \\n\" + \"\\033[0m\", clean_tweets[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
